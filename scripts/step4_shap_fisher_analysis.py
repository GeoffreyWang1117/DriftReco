import os
import torch
import shap
import numpy as np
import pandas as pd
from torch.utils.data import DataLoader
from sklearn.preprocessing import LabelEncoder
from scripts.step3_train_mlp import RecSysModel
from scripts.step2_dataloader import get_dataloader

# âœ… æ¨¡å‹ä¸è®¾å¤‡è®¾ç½®
script_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.abspath(os.path.join(script_dir, ".."))
model_path = os.path.join(project_root, "models", "mlp_model.pt")
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# âœ… åŠ è½½æ•°æ®
dataloader, dataset = get_dataloader(shuffle=False)
sample_batch = next(iter(dataloader))

# âœ… å®šä¹‰ SHAP åŒ…è£…å™¨ï¼ˆå¿…é¡»è¾“å‡º numpyï¼‰
class Wrapper(torch.nn.Module):
    def __init__(self, model):
        super().__init__()
        self.model = model

    def forward(self, inputs_numpy):
        inputs = torch.tensor(inputs_numpy, dtype=torch.long, device=device)
        user_id, item_id = inputs[:, 0], inputs[:, 1]
        with torch.no_grad():
            output = self.model(user_id, item_id).detach().cpu().numpy()
        return output

# âœ… æ„å»ºæ¨¡å‹å¹¶åŠ è½½å‚æ•°
model = RecSysModel(
    num_users=int(dataset.user_ids.max().item()) + 1,
    num_items=int(dataset.item_ids.max().item()) + 1
).to(device)
model.load_state_dict(torch.load(model_path, map_location=device))
model.eval()

wrapped_model = Wrapper(model)

# âœ… ç”Ÿæˆ SHAP è¾“å…¥ï¼ˆè½¬æ¢ä¸º numpyï¼‰
X_shap = torch.stack([sample_batch['user_id'], sample_batch['item_id']], dim=1).cpu().numpy()

# âœ… ä½¿ç”¨ KernelExplainerï¼ˆå¯¹é»‘ç›’æ¨¡å‹å…¼å®¹æ€§å¼ºï¼‰
print("â³ Running SHAP KernelExplainer...")
explainer = shap.KernelExplainer(wrapped_model, X_shap[:100])  # background
shap_values = explainer.shap_values(X_shap[:10])  # explain 10 samples

# âœ… è¾“å‡º SHAP å€¼
print("ğŸ“Š SHAP values (user_id, item_id):")
print(np.array(shap_values))

# âœ… Fisher ä¿¡æ¯ä¼°è®¡ï¼ˆåŸºäº MSE æ¢¯åº¦å¹³æ–¹ï¼‰
def estimate_fisher(model, dataloader):
    model.eval()
    fisher = {}
    for name, param in model.named_parameters():
        fisher[name] = torch.zeros_like(param)

    for batch in dataloader:
        model.zero_grad()
        user_id = batch["user_id"].to(device)
        item_id = batch["item_id"].to(device)
        rating = batch["rating"].to(device)
        pred = model(user_id, item_id)
        loss = torch.nn.functional.mse_loss(pred, rating)
        loss.backward()

        for name, param in model.named_parameters():
            if param.grad is not None:
                fisher[name] += param.grad.data ** 2

    for name in fisher:
        fisher[name] /= len(dataloader)

    return fisher

# âœ… è®¡ç®— Fisher ä¿¡æ¯
print("â³ Estimating Fisher Information...")
fisher_info = estimate_fisher(model, dataloader)

# âœ… è¾“å‡º Fisher ä¿¡æ¯æ‘˜è¦
print("ğŸ“ˆ Estimated Fisher Information (squared gradients):")
for name, value in fisher_info.items():
    print(f"{name}: mean={value.mean().item():.4f}, std={value.std().item():.4f}")